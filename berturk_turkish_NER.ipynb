{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPssparaBRj2LyxFYpohHfT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isiktopcu/bart/blob/main/berturk_turkish_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Toponymy Detection Using BERTurk in Turkish Tweets"
      ],
      "metadata": {
        "id": "jweG6gXERFnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're trying to find the location related tokens in Turkish tweets."
      ],
      "metadata": {
        "id": "iMoQ4sj4RZrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "\n",
        "model_name = \"savasy/bert-base-turkish-ner-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "tweet ='\"ðŸ“ŒHatay BÃ¼yÃ¼kÅŸehir Belediye BaÅŸkanÄ± LÃ¼tfÃ¼ SavaÅŸ: \"Åžu andaki demografik yapÄ±ya baktÄ±ÄŸÄ±nÄ±z zaman Suriyeliler, HataylÄ±lardan bir adÄ±m Ã¶nde. Hatay, Suriye ÅŸehri olma yolunda!\"'\n",
        "tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "#add special tokens [CLS] and [SEP]\n",
        "tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_tensor = torch.tensor([input_ids])\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_tensor)\n",
        "    predicted_labels = torch.argmax(outputs.logits, dim=2).squeeze(0).tolist()[1:-1]\n",
        "\n",
        "label_names = model.config.id2label\n",
        "\n",
        "locations = []\n",
        "\n",
        "\n",
        "current_location = \"\"\n",
        "for token, label_id in zip(tokens[1:-1], predicted_labels):\n",
        "    label = label_names[label_id]\n",
        "    if label == 'B-LOC':  # 'B-LOC' represents the beginning of a location entity\n",
        "        if current_location:\n",
        "            locations.append(current_location)\n",
        "        current_location = token\n",
        "    elif label == 'I-LOC':  # 'I-LOC' represents the continuation of a location entity\n",
        "        current_location += token\n",
        "\n",
        "if current_location:\n",
        "    locations.append(current_location)\n",
        "\n",
        "#join the location tokens and replace \"##\" with a blank\n",
        "locations_cleaned = [loc.replace(\"##\", \"\") for loc in locations]\n",
        "locations_string = ', '.join(locations_cleaned)\n",
        "print(\"Locations:\", locations_string)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bouJpNn6BqQK",
        "outputId": "f1c297ad-5f43-4e34-dd02-b9836c7592a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Locations: Hatay, Hatay, Suriye\n"
          ]
        }
      ]
    }
  ]
}